{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import eli5\n",
    "import pickle\n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestRegressor, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, scale, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_absolute_percentage_error, mean_squared_error, roc_auc_score, log_loss, precision_recall_fscore_support, mean_absolute_error, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loading data + X, y split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'founded_at', 'funding_rounds', 'funding_total_usd',\n",
       "       'milestones', 'relationships', 'lat', 'lng', 'category_code_biotech',\n",
       "       'category_code_consulting', 'category_code_ecommerce',\n",
       "       'category_code_education', 'category_code_enterprise',\n",
       "       'category_code_games_video', 'category_code_hardware',\n",
       "       'category_code_mobile', 'category_code_network_hosting',\n",
       "       'category_code_other', 'category_code_public_relations',\n",
       "       'category_code_search', 'category_code_software', 'category_code_web',\n",
       "       'country_code_BRA', 'country_code_CAN', 'country_code_DEU',\n",
       "       'country_code_ESP', 'country_code_FRA', 'country_code_GBR',\n",
       "       'country_code_IND', 'country_code_IRL', 'country_code_ISR',\n",
       "       'country_code_NLD', 'country_code_USA', 'country_code_other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:\\Internship Database\\companies1.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "X = df.copy()\n",
    "y = df[['status', 'isClosed', 'active_days']]\n",
    "yStatus = X.pop('status')\n",
    "yClosed = X.pop('isClosed')\n",
    "yActive = X.pop('active_days')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['founded_at', 'funding_rounds', 'funding_total_usd', 'milestones',\n",
       "       'relationships'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[[\n",
    "    'founded_at', 'funding_rounds', 'funding_total_usd', 'milestones', 'relationships'\n",
    "]]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    39273\n",
      "0     3965\n",
      "Name: isClosed, dtype: int64\n",
      "3    38864\n",
      "0     2782\n",
      "1     1183\n",
      "2      409\n",
      "Name: status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "closed = yClosed.value_counts(); print(closed)\n",
    "status = yStatus.value_counts(); print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train, test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "yStatus_train = y_train.iloc[:,0]\n",
    "yClosed_train = y_train.iloc[:,1]\n",
    "yActive_train = y_train.iloc[:,2]\n",
    "\n",
    "yStatus_test = y_test.iloc[:,0]\n",
    "yClosed_test = y_test.iloc[:,1]\n",
    "yActive_test = y_test.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(random_state=0)\n",
    "smote = SMOTE()\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ensemble learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('QDA', qda), ('RandomForest', rf)]\n",
    "final_estimator = GradientBoostingClassifier()\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = Pipeline([\n",
    "    ('stdscaler', stdscaler),\n",
    "    ('pca', pca),\n",
    "    ('classifier', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  89.34 %\n"
     ]
    }
   ],
   "source": [
    "model_ensemble.fit(X_train, yStatus_train)\n",
    "pred = model_ensemble.predict(X_test)\n",
    "print('test accuracy = ', round(accuracy_score(yStatus_test, pred)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.273     0.005     0.011       560\n",
      "           1      0.029     0.004     0.007       248\n",
      "           2      0.375     0.120     0.182        75\n",
      "           3      0.899     0.993     0.944      7765\n",
      "\n",
      "    accuracy                          0.893      8648\n",
      "   macro avg      0.394     0.281     0.286      8648\n",
      "weighted avg      0.829     0.893     0.850      8648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yStatus_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qda = Pipeline([\n",
    "    ('stdscaler', stdscaler),\n",
    "    ('pca', pca),\n",
    "    ('classifier', qda)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  88.84 %\n"
     ]
    }
   ],
   "source": [
    "model_qda.fit(X_train, yClosed_train)\n",
    "pred = model_qda.predict(X_test)\n",
    "print('test accuracy = ', round(accuracy_score(yClosed_test, pred)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.230     0.083     0.122       808\n",
      "           1      0.911     0.971     0.940      7840\n",
      "\n",
      "    accuracy                          0.888      8648\n",
      "   macro avg      0.571     0.527     0.531      8648\n",
      "weighted avg      0.848     0.888     0.864      8648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yClosed_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = Pipeline([\n",
    "    ('stdscaler', stdscaler),\n",
    "    ('pca', pca),\n",
    "    ('classifier', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy =  88.6 %\n"
     ]
    }
   ],
   "source": [
    "model_rf.fit(X_train, yStatus_train)\n",
    "pred = model_rf.predict(X_test)\n",
    "print('test accuracy = ', round(accuracy_score(yStatus_test, pred)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.262     0.048     0.082       808\n",
      "           1      0.837     0.005     0.010      7840\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.009      8648\n",
      "   macro avg      0.275     0.013     0.023      8648\n",
      "weighted avg      0.783     0.009     0.017      8648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yClosed_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_ensemble, open('D:\\Internship Database\\ensemble.pkl', 'wb'))\n",
    "pickle.dump(model_qda, open('D:\\Internship Database\\qda.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_rf, open('D:\\Internship Database\\mod_rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the model :\n",
    "# pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
    "# pickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8304880a3e767ad58ed1695f5214ef77ebbb8fdf4513a7eb4c0fbb1ff3deb86b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
